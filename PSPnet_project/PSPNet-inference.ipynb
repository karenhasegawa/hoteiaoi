{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":69},"executionInfo":{"elapsed":4604,"status":"ok","timestamp":1656401015018,"user":{"displayName":"長谷川佳蓮","userId":"18431432929582350846"},"user_tz":-540},"id":"IsLkudrV0NMz","outputId":"360a43f4-7cc9-44f2-82e3-88c0af562ae0"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":4851,"status":"ok","timestamp":1656401026270,"user":{"displayName":"長谷川佳蓮","userId":"18431432929582350846"},"user_tz":-540},"id":"mfYtjgWtAfjo"},"outputs":[],"source":["import os \n","import os.path as osp\n","import math\n","import time\n","import pandas as pd\n","import numpy as np\n","import cv2\n","\n","import torch\n","import torch.utils.data as data\n","import torch.nn as nn\n","import torch.nn.init as init\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchvision import transforms\n","\n","import matplotlib.pyplot as plt\n","\n","from PIL import Image, ImageOps, ImageFilter\n","\n","import re\n","import glob"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["PATH = 'C:/Users/Karen/Documents/PSPNet'\n","ROOTPH = 'C:/Users/Karen/Documents/PSPNet/10m_image'\n","STADIED_PATH = 'C:/Users/Karen/Documents/PSPNet/dataset_voc_10m_(1)+(3)/weights/pspnet50_15.pth'"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":4750,"status":"ok","timestamp":1656401537717,"user":{"displayName":"長谷川佳蓮","userId":"18431432929582350846"},"user_tz":-540},"id":"Hcc9wiOVRCOF"},"outputs":[{"name":"stdout","output_type":"stream","text":["-----------exist folder------------------\n","folder: C:\\Users\\Karen\\Documents\\PSPNet\\10m_image\n","['C:\\\\Users\\\\Karen\\\\Documents\\\\PSPNet\\\\10m_image\\\\DJI_0001.jpg', 'C:\\\\Users\\\\Karen\\\\Documents\\\\PSPNet\\\\10m_image\\\\DJI_0002.jpg', 'C:\\\\Users\\\\Karen\\\\Documents\\\\PSPNet\\\\10m_image\\\\DJI_0003.jpg']\n","['DJI_0001', 'DJI_0002', 'DJI_0003']\n","ネットワーク設定完了：学習済みの重みをロードしました。\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Karen\\AppData\\Local\\Temp\\ipykernel_12060\\1331883916.py:34: DeprecationWarning: BICUBIC is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BICUBIC instead.\n","  img = img.resize((self.input_size, self.input_size),Image.BICUBIC)\n"]},{"name":"stdout","output_type":"stream","text":["torch.Size([2, 3, 475, 475])\n"]}],"source":["def make_datapath_list(rootpath):\n","    \"\"\"\n","    学習、検証の画像データとアノテーションデータへのファイルパスリストを作成する。\n","\n","    Parameters\n","    ----------\n","    rootpath : str\n","        データフォルダへのパス\n","\n","    Returns\n","    -------\n","    ret : train_img_list, train_anno_list, val_img_list, val_anno_list\n","        データへのパスを格納したリスト\n","    \"\"\"\n","\n","    # 画像ファイルへのパス\n","    imgpath_template = glob.glob(rootpath + '/*')\n","\n","    id_names = list()\n","    # ファイルのID（ファイル名）を取得する\n","    for imgpath in imgpath_template:\n","        splits = imgpath.split('\\\\')\n","        id_names.append(splits[len(splits)-1][:-4])\n","\n","    return imgpath_template,id_names\n","\n","    \n","class DataTransform():\n","\n","    def __init__(self,input_size):\n","        self.input_size = input_size\n","\n","    def __call__(self,img):\n","        img = img.resize((self.input_size, self.input_size),Image.BICUBIC)\n","        img = torch.from_numpy(np.array(img, dtype=float).transpose(2,0,1)) / 255\n","        return img\n","\n","class VOCDataset(data.Dataset):\n","    \"\"\"\n","    VOC2012のDatasetを作成するクラス。PyTorchのDatasetクラスを継承。\n","\n","    Attributes\n","    ----------\n","    img_list : リスト\n","        画像のパスを格納したリスト\n","    anno_list : リスト\n","        アノテーションへのパスを格納したリスト\n","    phase : 'train' or 'test'\n","        学習か訓練かを設定する。\n","    transform : object\n","        前処理クラスのインスタンス\n","    \"\"\"\n","\n","    def __init__(self, img_list, transform,id_names):\n","        self.img_list = img_list\n","        self.transform = transform\n","        self.id_names = id_names\n","\n","    def __getitem__(self, index):\n","        '''\n","        前処理をした画像のTensor形式のデータとアノテーションを取得\n","        '''\n","        img = self.pull_item(index)\n","        return img\n","    \n","    def __len__(self):\n","        '''画像の枚数を返す'''\n","        return len(self.img_list)\n","\n","    def id_list(self,index):\n","        idname = self.id_names[index]\n","        return idname\n","\n","    def pull_item(self,index):\n","        '''画像のTensor形式のデータ、アノテーションを取得する'''\n","\n","        # 1. 画像読み込み\n","        image_file_path = self.img_list[index]\n","        img = Image.open(image_file_path)   # [高さ][幅][色RGB]\n","\n","        # 3. 前処理を実施\n","        img = self.transform(img)\n","\n","        return img\n","\n","\n","class PSPNet(nn.Module):\n","    def __init__(self, n_classes):\n","        super(PSPNet, self).__init__()\n","\n","        # パラメータ設定\n","        block_config = [3, 4, 6, 3]  # resnet50\n","        img_size = 475\n","        img_size_8 = 60  # img_sizeの1/8に\n","\n","        # 4つのモジュールを構成するサブネットワークの用意\n","        self.feature_conv = FeatureMap_convolution()\n","        self.feature_res_1 = ResidualBlockPSP(\n","            n_blocks=block_config[0], in_channels=128, mid_channels=64, out_channels=256, stride=1, dilation=1)\n","        self.feature_res_2 = ResidualBlockPSP(\n","            n_blocks=block_config[1], in_channels=256, mid_channels=128, out_channels=512, stride=2, dilation=1)\n","        self.feature_dilated_res_1 = ResidualBlockPSP(\n","            n_blocks=block_config[2], in_channels=512, mid_channels=256, out_channels=1024, stride=1, dilation=2)\n","        self.feature_dilated_res_2 = ResidualBlockPSP(\n","            n_blocks=block_config[3], in_channels=1024, mid_channels=512, out_channels=2048, stride=1, dilation=4)\n","\n","        self.pyramid_pooling = PyramidPooling(in_channels=2048, pool_sizes=[\n","            6, 3, 2, 1], height=img_size_8, width=img_size_8)\n","\n","        self.decode_feature = DecodePSPFeature(\n","            height=img_size, width=img_size, n_classes=n_classes)\n","\n","        self.aux = AuxiliaryPSPlayers(\n","            in_channels=1024, height=img_size, width=img_size, n_classes=n_classes)\n","\n","    def forward(self, x):\n","        x = self.feature_conv(x)\n","        x = self.feature_res_1(x)\n","        x = self.feature_res_2(x)\n","        x = self.feature_dilated_res_1(x)\n","\n","        output_aux = self.aux(x)  # Featureモジュールの途中をAuxモジュールへ\n","\n","        x = self.feature_dilated_res_2(x)\n","\n","        x = self.pyramid_pooling(x)\n","        output = self.decode_feature(x)\n","\n","        return (output, output_aux)\n","\n","\n","class conv2DBatchNormRelu(nn.Module):#net#FeatureMap_convolution\n","    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, dilation, bias):\n","        super(conv2DBatchNormRelu, self).__init__()\n","        self.conv = nn.Conv2d(in_channels, out_channels,\n","                              kernel_size, stride, padding, dilation, bias=bias)\n","        self.batchnorm = nn.BatchNorm2d(out_channels)\n","        self.relu = nn.ReLU(inplace=True)\n","        # inplase設定で入力を保存せずに出力を計算し、メモリ削減する\n","\n","    def forward(self, x):\n","        x = self.conv(x)\n","        x = self.batchnorm(x)\n","        outputs = self.relu(x)\n","\n","        return outputs\n","\n","\n","class FeatureMap_convolution(nn.Module):#net\n","    def __init__(self):\n","        '''構成するネットワークを用意'''\n","        super(FeatureMap_convolution, self).__init__()\n","\n","        # 畳み込み層1\n","        in_channels, out_channels, kernel_size, stride, padding, dilation, bias = 3, 64, 3, 2, 1, 1, False\n","        self.cbnr_1 = conv2DBatchNormRelu(\n","            in_channels, out_channels, kernel_size, stride, padding, dilation, bias)\n","\n","        # 畳み込み層2\n","        in_channels, out_channels, kernel_size, stride, padding, dilation, bias = 64, 64, 3, 1, 1, 1, False\n","        self.cbnr_2 = conv2DBatchNormRelu(\n","            in_channels, out_channels, kernel_size, stride, padding, dilation, bias)\n","\n","        # 畳み込み層3\n","        in_channels, out_channels, kernel_size, stride, padding, dilation, bias = 64, 128, 3, 1, 1, 1, False\n","        self.cbnr_3 = conv2DBatchNormRelu(\n","            in_channels, out_channels, kernel_size, stride, padding, dilation, bias)\n","\n","        # MaxPooling層\n","        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n","\n","    def forward(self, x):\n","        x = self.cbnr_1(x)\n","        x = self.cbnr_2(x)\n","        x = self.cbnr_3(x)\n","        outputs = self.maxpool(x)\n","        return outputs\n","\n","\n","class ResidualBlockPSP(nn.Sequential):#net\n","    def __init__(self, n_blocks, in_channels, mid_channels, out_channels, stride, dilation):\n","        super(ResidualBlockPSP, self).__init__()\n","\n","        # bottleNeckPSPの用意\n","        self.add_module(\n","            \"block1\",\n","            bottleNeckPSP(in_channels, mid_channels,\n","                          out_channels, stride, dilation)\n","        )\n","\n","        # bottleNeckIdentifyPSPの繰り返しの用意\n","        for i in range(n_blocks - 1):\n","            self.add_module(\n","                \"block\" + str(i+2),\n","                bottleNeckIdentifyPSP(\n","                    out_channels, mid_channels, stride, dilation)\n","            )\n","\n","\n","class conv2DBatchNorm(nn.Module):\n","    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, dilation, bias):\n","        super(conv2DBatchNorm, self).__init__()\n","        self.conv = nn.Conv2d(in_channels, out_channels,\n","                              kernel_size, stride, padding, dilation, bias=bias)\n","        self.batchnorm = nn.BatchNorm2d(out_channels)\n","\n","    def forward(self, x):\n","        x = self.conv(x)\n","        outputs = self.batchnorm(x)\n","\n","        return outputs\n","\n","\n","class bottleNeckPSP(nn.Module):#net##ResidualBlockPSP\n","    def __init__(self, in_channels, mid_channels, out_channels, stride, dilation):\n","        super(bottleNeckPSP, self).__init__()\n","\n","        self.cbr_1 = conv2DBatchNormRelu(\n","            in_channels, mid_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False)\n","        self.cbr_2 = conv2DBatchNormRelu(\n","            mid_channels, mid_channels, kernel_size=3, stride=stride, padding=dilation, dilation=dilation, bias=False)\n","        self.cb_3 = conv2DBatchNorm(\n","            mid_channels, out_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False)\n","\n","        # スキップ結合\n","        self.cb_residual = conv2DBatchNorm(\n","            in_channels, out_channels, kernel_size=1, stride=stride, padding=0, dilation=1, bias=False)\n","\n","        self.relu = nn.ReLU(inplace=True)\n","\n","    def forward(self, x):\n","        conv = self.cb_3(self.cbr_2(self.cbr_1(x)))\n","        residual = self.cb_residual(x)\n","        return self.relu(conv + residual)\n","\n","\n","class bottleNeckIdentifyPSP(nn.Module):#net##ResidualBlockPSP\n","    def __init__(self, in_channels, mid_channels, stride, dilation):\n","        super(bottleNeckIdentifyPSP, self).__init__()\n","\n","        self.cbr_1 = conv2DBatchNormRelu(\n","            in_channels, mid_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False)\n","        self.cbr_2 = conv2DBatchNormRelu(\n","            mid_channels, mid_channels, kernel_size=3, stride=1, padding=dilation, dilation=dilation, bias=False)\n","        self.cb_3 = conv2DBatchNorm(\n","            mid_channels, in_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False)\n","        self.relu = nn.ReLU(inplace=True)\n","\n","    def forward(self, x):\n","        conv = self.cb_3(self.cbr_2(self.cbr_1(x)))\n","        residual = x\n","        return self.relu(conv + residual)\n","\n","\n","class PyramidPooling(nn.Module):#net\n","    def __init__(self, in_channels, pool_sizes, height, width):\n","        super(PyramidPooling, self).__init__()\n","\n","        # forwardで使用する画像サイズ\n","        self.height = height\n","        self.width = width\n","\n","        # 各畳み込み層の出力チャネル数\n","        out_channels = int(in_channels / len(pool_sizes))\n","\n","        # 各畳み込み層を作成\n","        # この実装方法は愚直すぎてfor文で書きたいところですが、分かりやすさを優先しています\n","        # pool_sizes: [6, 3, 2, 1]\n","        self.avpool_1 = nn.AdaptiveAvgPool2d(output_size=pool_sizes[0])\n","        self.cbr_1 = conv2DBatchNormRelu(\n","            in_channels, out_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False)\n","\n","        self.avpool_2 = nn.AdaptiveAvgPool2d(output_size=pool_sizes[1])\n","        self.cbr_2 = conv2DBatchNormRelu(\n","            in_channels, out_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False)\n","\n","        self.avpool_3 = nn.AdaptiveAvgPool2d(output_size=pool_sizes[2])\n","        self.cbr_3 = conv2DBatchNormRelu(\n","            in_channels, out_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False)\n","\n","        self.avpool_4 = nn.AdaptiveAvgPool2d(output_size=pool_sizes[3])\n","        self.cbr_4 = conv2DBatchNormRelu(\n","            in_channels, out_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False)\n","\n","    def forward(self, x):\n","\n","        out1 = self.cbr_1(self.avpool_1(x))\n","        out1 = F.interpolate(out1, size=(\n","            self.height, self.width), mode=\"bilinear\", align_corners=True)\n","\n","        out2 = self.cbr_2(self.avpool_2(x))\n","        out2 = F.interpolate(out2, size=(\n","            self.height, self.width), mode=\"bilinear\", align_corners=True)\n","\n","        out3 = self.cbr_3(self.avpool_3(x))\n","        out3 = F.interpolate(out3, size=(\n","            self.height, self.width), mode=\"bilinear\", align_corners=True)\n","\n","        out4 = self.cbr_4(self.avpool_4(x))\n","        out4 = F.interpolate(out4, size=(\n","            self.height, self.width), mode=\"bilinear\", align_corners=True)\n","\n","        # 最終的に結合させる、dim=1でチャネル数の次元で結合\n","        output = torch.cat([x, out1, out2, out3, out4], dim=1)\n","\n","        return output\n","\n","\n","class DecodePSPFeature(nn.Module):#net\n","    def __init__(self, height, width, n_classes):\n","        super(DecodePSPFeature, self).__init__()\n","\n","        # forwardで使用する画像サイズ\n","        self.height = height\n","        self.width = width\n","\n","        self.cbr = conv2DBatchNormRelu(\n","            in_channels=4096, out_channels=512, kernel_size=3, stride=1, padding=1, dilation=1, bias=False)\n","        self.dropout = nn.Dropout2d(p=0.1)\n","        self.classification = nn.Conv2d(\n","            in_channels=512, out_channels=n_classes, kernel_size=1, stride=1, padding=0)\n","\n","    def forward(self, x):\n","        x = self.cbr(x)\n","        x = self.dropout(x)\n","        x = self.classification(x)\n","        output = F.interpolate(\n","            x, size=(self.height, self.width), mode=\"bilinear\", align_corners=True)\n","\n","        return output\n","\n","\n","class AuxiliaryPSPlayers(nn.Module):#net\n","    def __init__(self, in_channels, height, width, n_classes):\n","        super(AuxiliaryPSPlayers, self).__init__()\n","\n","        # forwardで使用する画像サイズ\n","        self.height = height\n","        self.width = width\n","\n","        self.cbr = conv2DBatchNormRelu(\n","            in_channels=in_channels, out_channels=256, kernel_size=3, stride=1, padding=1, dilation=1, bias=False)\n","        self.dropout = nn.Dropout2d(p=0.1)\n","        self.classification = nn.Conv2d(\n","            in_channels=256, out_channels=n_classes, kernel_size=1, stride=1, padding=0)\n","\n","    def forward(self, x):\n","        x = self.cbr(x)\n","        x = self.dropout(x)\n","        x = self.classification(x)\n","        output = F.interpolate(\n","            x, size=(self.height, self.width), mode=\"bilinear\", align_corners=True)\n","\n","        return output\n","\n","def run_model(net, dataloader):\n","\n","    ##CPU／GPUの切り替え\n","    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","    net.to(device)\n","    print(\"使用デバイス：\", device)\n","    print(torch.cuda.is_available())\n","\n","    torch.backends.cudnn.benchmark = True\n","\n","    # 画像の枚数\n","    num_imgs = len(dataloader.dataset)\n","\n","    batch_size = dataloader.batch_size\n","\n","    net.eval()   # モデルを検証モードに\n","\n","    # データローダーからminibatchずつ取り出すループ\n","    for imges in dataloader:\n","\n","        img_stock = []\n","        picup_img = []\n","\n","        for r in range(num_imgs):\n","            \n","            img = imges[r, :, :, :].numpy().transpose(2, 1, 0)\n","            img = np.fliplr(img)\n","            img = np.rot90(img, 1)\n","\n","            picup_img.append(img)\n","\n","            img = img.transpose(2, 1, 0)\n","            new_imge = torch.from_numpy(img.astype(np.float64)).clone()\n","            img_stock.append(new_imge)\n","                    \n","        new_imges = torch.stack(img_stock)\n","    \n","        # ミニバッチがサイズが1だと、バッチノーマライゼーションでエラーになるのでさける\n","        if new_imges.size()[0] == 1:\n","            return\n","\n","        # GPUが使えるならGPUにデータを送る\n","        new_imges = new_imges.to(device, dtype=torch.float)\n","\n","        outputs = net(new_imges)\n","        output = outputs[0]#AuxLoss側は無視　yサイズはtorch.Size()\n","\n","        device2 = torch.device('cpu')\n","        output = output.to(device2)#CPU／GPUの切り替え\n","\n","        #結果を保存\n","        with torch.no_grad():\n","            for r in range(len(output)):\n","                out_img = output[r]\n","                out_img = out_img.numpy()\n","                out_img = np.argmax(out_img, axis=0)#一番大きい要素のインデックスを返す(ピクセル毎に確信度が最大のクラスを求める\n","                class_img = Image.fromarray(255-np.uint8(out_img)*255, mode=\"P\")\n","                class_img.putpalette([255,255,0])#黄色に設定\n","                class_img = class_img.convert('RGB')\n","                result_img = Image.new('RGBA', class_img.size, (0, 0, 0, 0))\n","                for x in range(475):\n","                    for y in range(475):\n","                        #学習結果画像のピクセルデータを取得\n","                        ##黄色\n","                        pixel = class_img.getpixel((x, y))\n","                \n","                        if pixel == (255, 255, 0):\n","                            result_img.putpixel((x, y), (255, 255, 0, 150))#yellow\n","                        \n","                img = Image.fromarray((picup_img[r]*255).astype(np.uint8))\n","                result_img = Image.alpha_composite(img.convert('RGBA'), class_img)\n","                result_img = cv2.cvtColor(np.asarray(result_img), cv2.COLOR_RGBA2BGRA)\n","                if os.path.exists(PATH + '/pspnet_inference_result') == False:\n","                    os.mkdir(PATH + '/pspnet_inference_result')\n","                cv2.imwrite(PATH + '/pspnet_inference_result/'+dataloader.dataset.id_list(r)+'.jpg', result_img)\n","        \n","    return\n","\n","\n","\"\"\"セマンティックセグメンテーションの推論\"\"\"\n","\n","##ファイルパスリストの作成\n","rootpath = os.path.abspath(ROOTPH)\n","if os.path.exists(rootpath):\n","  print('-----------exist folder------------------')\n","  print('folder:',rootpath)\n","\n","imgpath_list,id_names_list = make_datapath_list(rootpath=rootpath)\n","\n","print(imgpath_list[0:3])\n","print(id_names_list[0:3])\n","\n","##PSPnetの用意\n","net = PSPNet(n_classes = 2)\n","\n","#学習済みパラメータをロード\n","state_dict = torch.load(STADIED_PATH, map_location={\"cuda:0\": \"cpu\"})\n","net.load_state_dict(state_dict)\n","print(\"ネットワーク設定完了：学習済みの重みをロードしました。\")\n","\n","\"\"\" データセット作成\"\"\"\n","dataset = VOCDataset(imgpath_list,transform=DataTransform(input_size=475),id_names=id_names_list)\n","\n","\"\"\"データローダーの作成\"\"\"\n","dataloader = data.DataLoader(dataset, batch_size=2, shuffle=False)\n","\n","# 動作の確認\n","batch_iterator = iter(dataloader)  # イタレータに変換\n","imges= next(batch_iterator)  # 1番目の要素を取り出す\n","print(imges.size())  # torch.Size([8, 3, 475, 475])\n"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"CFlbUBkL9vdZ"},"outputs":[{"name":"stdout","output_type":"stream","text":["使用デバイス： cuda:0\n","True\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Karen\\AppData\\Local\\Temp\\ipykernel_12060\\1331883916.py:34: DeprecationWarning: BICUBIC is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BICUBIC instead.\n","  img = img.resize((self.input_size, self.input_size),Image.BICUBIC)\n"]},{"ename":"IndexError","evalue":"index 2 is out of bounds for dimension 0 with size 2","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[1;32mIn [4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m run_model(net, dataloader)\n","Cell \u001b[1;32mIn [3], line 381\u001b[0m, in \u001b[0;36mrun_model\u001b[1;34m(net, dataloader)\u001b[0m\n\u001b[0;32m    377\u001b[0m picup_img \u001b[39m=\u001b[39m []\n\u001b[0;32m    379\u001b[0m \u001b[39mfor\u001b[39;00m r \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_imgs):\n\u001b[1;32m--> 381\u001b[0m     img \u001b[39m=\u001b[39m imges[r, :, :, :]\u001b[39m.\u001b[39mnumpy()\u001b[39m.\u001b[39mtranspose(\u001b[39m2\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m)\n\u001b[0;32m    382\u001b[0m     img \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mfliplr(img)\n\u001b[0;32m    383\u001b[0m     img \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrot90(img, \u001b[39m1\u001b[39m)\n","\u001b[1;31mIndexError\u001b[0m: index 2 is out of bounds for dimension 0 with size 2"]}],"source":["run_model(net, dataloader)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"PSPNet.ipynb","version":""},"gpuClass":"standard","kernelspec":{"display_name":"PSPNet_GPU","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13 (main, Oct 13 2022, 21:23:06) [MSC v.1916 64 bit (AMD64)]"},"vscode":{"interpreter":{"hash":"ce5d6266c4931b9244e5d3d471288fdc578be2cdd6e87eacd473f02adff06818"}}},"nbformat":4,"nbformat_minor":0}
